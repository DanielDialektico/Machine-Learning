{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9ORDZosTQ2c3TY2xyweCO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielDialektico/Machine-Learning/blob/main/Notebooks/Aprendizaje%20No%20Supervisado/Agrupaci%C3%B3n/LDA_Modelado_de_T%C3%B3picos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este espacio de trabajo contiene la aplicación de un algoritmo de aprendizaje no supervisado de procesamiento de lenguaje natural a un conjunto de datos de reseñas de clientes de una tienda departamental.\n",
        "\n",
        "El modelo utilizado fue el LDA ()Latent Dirichlet Allocation), el cual se utiliza para modelado de tópicos, es decir, agrupación de términos en categorías (permite superposición de términos, es decir, cada término puede estar asociado a más de una clase).\n"
      ],
      "metadata": {
        "id": "XgRA9L6yH6uE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de datos"
      ],
      "metadata": {
        "id": "PSMOSP7QIg8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el siguiente fragmento de código se instalan y cargan las librerías necesarias."
      ],
      "metadata": {
        "id": "f-W3fNx-IkHw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO0kPR9iC8Lx"
      },
      "outputs": [],
      "source": [
        "!python3 -m spacy download es_core_news_sm\n",
        "!pip install pyLDAvis\n",
        "!pip install pyLDAvis.gensim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import FreqDist\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import es_core_news_sm\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "nltk.download('punkt')\n",
        "\n",
        "#Se ignoran las alertas.\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el siguiente bloque se carga y filtra el conjunto de datos, el cual se obtuvo scrapeando las reseñas de Google Maps utilizando una API:"
      ],
      "metadata": {
        "id": "s9ODnpb9IqTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se carga el conjunto de datos.\n",
        "reviews = pd.read_csv('https://raw.githubusercontent.com/DanielDialektico/Machine-Learning/main/Conjuntos%20de%20datos/Rese%C3%B1as.csv')\n",
        "reviews = reviews[\"Opinión\"].dropna().reset_index(drop = True)"
      ],
      "metadata": {
        "id": "TjXL5dPfD2pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploración de datos"
      ],
      "metadata": {
        "id": "dIN9wck0Jyro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se procede a graficar las 20 palabras más frecuentes."
      ],
      "metadata": {
        "id": "CaorRz_AIxUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para graficar términos más frecuentes\n",
        "def freq_words(x, terms = 30):\n",
        "  all_words = ' '.join([text for text in x])\n",
        "  all_words = all_words.split()\n",
        "\n",
        "  fdist = FreqDist(all_words)\n",
        "  words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n",
        "\n",
        "  # selecting top 20 most frequent words\n",
        "  d = words_df.nlargest(columns=\"count\", n = terms)\n",
        "  plt.figure(figsize=(20,5))\n",
        "  ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n",
        "  ax.set(ylabel = 'Conteo')\n",
        "  ax.set(xlabel = 'Término')\n",
        "  plt.xticks(rotation=45, ha=\"right\")\n",
        "  plt.show()\n",
        "\n",
        "freq_words(reviews)"
      ],
      "metadata": {
        "id": "JodkCuM_F1sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que las palabras más frecuentes no aportan información relevante sobre las opiniones de los clientes, se procede a preprocesar el conjunto de datos."
      ],
      "metadata": {
        "id": "eRdYBUHdJBnB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento"
      ],
      "metadata": {
        "id": "52tLOcC-J2T5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la siguiente celda se preprocesa el conjunto de datos aplicando los siguientes ajustes:\n",
        "\n",
        "\n",
        "\n",
        "*   Se tokenizan las frases.\n",
        "*   Se convierten todas las letras a minúsculas.\n",
        "*   Se quitan caracteres no alfanuméricos.\n",
        "*   Se eliminan stop words.\n",
        "*   Se remueven adjetivos.\n",
        "*   Se lematizan los textos.\n",
        "*   Se remueven los acentos ortográficos.\n",
        "\n",
        "Al final, se vuelven a graficar los términos más frecuentes."
      ],
      "metadata": {
        "id": "UjOKlmC9J6Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = es_core_news_sm.load()\n",
        "\n",
        "def remove_w(data_set):\n",
        "  words = [\"google\", \"traducción\", \"jeje\", \"gustar\", \"despota\", \"tener\"]\n",
        "  for i in words:\n",
        "    data_set = data_set.str.replace(i, \"\")\n",
        "  return data_set\n",
        "\n",
        "#reviews = remove_w(reviews)\n",
        "\n",
        "drop_index = []\n",
        "\n",
        "for i in range(len(reviews)):\n",
        "  text = nlp(reviews.iloc[i])\n",
        "  words = [t.orth_ for t in text if not t.is_punct | t.is_stop]\n",
        "  lexical_tokens = nlp(' '.join([t.lower() for t in words if len(t) > 3 and t.isalpha()]).replace(\"tender \",\"tienda \"))\n",
        "  lemmas_no_pron = ' '.join([tok.lemma_ for tok in lexical_tokens if tok.pos_ != 'PRON' and tok.pos_ != 'ADJ'])\n",
        "  reviews.iat[i] = lemmas_no_pron\n",
        "  lemmas_as_word = ' '.join(lemmas_no_pron)\n",
        "  if lemmas_as_word == '':\n",
        "    drop_index.append(i)\n",
        "\n",
        "reviews = reviews.drop(drop_index)\n",
        "\n",
        "reviews = remove_w(reviews)\n",
        "reviews = reviews.str.replace(\"tender\", \"tienda\")\n",
        "reviews = reviews.str.replace(\"personar\", \"personal\")\n",
        "reviews = reviews.str.replace(\"preciar\", \"precio\")\n",
        "reviews = reviews.str.replace(\"mesar\", \"meses\")\n",
        "\n",
        "\n",
        "def remove_accent(data_set):\n",
        "  accent = [\"á\",\"é\",\"í\",\"ó\",\"ú\"]\n",
        "  drop_accent = [\"a\", \"e\", \"i\", \"o\", \"u\"]\n",
        "  for i in range(len(accent)):\n",
        "    data_set = data_set.str.replace(accent[i], drop_accent[i])\n",
        "  return data_set\n",
        "\n",
        "reviews = remove_accent(reviews)\n",
        "\n",
        "reviews = reviews.apply(lambda x: word_tokenize(x))\n",
        "\n",
        "reviews_list = reviews.apply(lambda x: ' '.join([j for j in x]))\n",
        "reviews_list = reviews_list.values.tolist()\n",
        "freq_words(reviews_list, 35)"
      ],
      "metadata": {
        "id": "BwC5m9f7EtoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que se ha preprocesado el conjunto de datos, se aplica el algoritmo de aprendizaje no supervisado para la agrupación de términos en categorías.\n",
        "\n",
        "El siguiente código ajusta el modelo a los datos, e imprime los principales términos que componen a cada una de las 4 categorías generadas."
      ],
      "metadata": {
        "id": "yw_pGZXQKoD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = corpora.Dictionary(reviews)\n",
        "\n",
        "doc_term_matrix = [dictionary.doc2bow(rev) for rev in reviews]\n",
        "\n",
        "LDA = gensim.models.ldamodel.LdaModel\n",
        "\n",
        "# Build LDA model\n",
        "lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=4, random_state = 100,\n",
        "                chunksize=100, passes=50)\n",
        "\n",
        "lda_model.print_topics()"
      ],
      "metadata": {
        "id": "xFetuNeoGIsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, se visualizan los resultados:"
      ],
      "metadata": {
        "id": "qfsz8ZubK8Db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = gensimvis.prepare(lda_model, doc_term_matrix, dictionary)\n",
        "vis"
      ],
      "metadata": {
        "id": "fMOTMZ1YG4kw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}